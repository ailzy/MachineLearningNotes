{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算法实现与模拟实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模拟数据产生器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, sys, warnings, traceback\n",
    "import numpy as np\n",
    "from data import ar_error_cov1, ar_error_cov2, ar_x_cov, data_generator1\n",
    "from smrce import training, l1_norm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.5, 0.25, 0.125, 0.0625, 0.03125],\n",
       " [0.5, 1.0, 0.5, 0.25, 0.125, 0.0625],\n",
       " [0.25, 0.5, 1.0, 0.5, 0.25, 0.125],\n",
       " [0.125, 0.25, 0.5, 1.0, 0.5, 0.25],\n",
       " [0.0625, 0.125, 0.25, 0.5, 1.0, 0.5],\n",
       " [0.03125, 0.0625, 0.125, 0.25, 0.5, 1.0]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_covariance_E1 = ar_error_cov1(6, 0.5)\n",
    "matrix_precision_E1 = [[int(y*10000)/100.0 for y in x] for x in np.linalg.inv(matrix_covariance_E1).tolist()]\n",
    "matrix_covariance_E1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.38, -2.76, -0.28, -0.35, -0.25, -0.41],\n",
       " [-2.76, 6.08, -2.6, -0.09, -0.22, -0.25],\n",
       " [-0.28, -2.6, 6.09, -2.6, -0.09, -0.35],\n",
       " [-0.35, -0.09, -2.6, 6.09, -2.6, -0.28],\n",
       " [-0.25, -0.22, -0.09, -2.6, 6.08, -2.76],\n",
       " [-0.41, -0.25, -0.35, -0.28, -2.76, 4.38]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_covariance_E2 = ar_error_cov2(6, 0.95)\n",
    "matrix_precision_E2 = [[int(y*100)/ 100.0 for y in x] for x in np.linalg.inv(matrix_covariance_E2).tolist()]\n",
    "matrix_precision_E2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_split(X, Y, n_splits=4):\n",
    "    D = np.concatenate((X, Y), axis=1)\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    P = X.shape[1]\n",
    "    for train, test in kf.split([i for i in range(N)]):\n",
    "        # training\n",
    "        D_train, D_test = D[train], D[test]\n",
    "        X_train, Y_train = D_train[:,:P], D_train[:,P:]\n",
    "        X_test, Y_test = D_test[:,:P], D_test[:,P:]\n",
    "        yield X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验参数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_setup_list = \\\n",
    "[[s1, s2, P, Q, N, roE, n_split, n_repeat] for s1 in [0.1, 0.5] \n",
    " for s2 in [0.5] \n",
    " for P in [20, 50] \n",
    " for Q in [20, 50] \n",
    " for N in [50] \n",
    " for roE in [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    " for n_split in [3]\n",
    " for n_repeat in [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, Experiment With Parameters -- [0.1, 0.5, 20, 20, 50, 0.1]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 20 20 50 0.1 0.018121967816588983 0.12116977331090428 0.005871356674428618 0.007610094789978464 0.008671892052970618 0.12806305788764857 0.021557431460553764 25 400 11\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 20, 20, 50, 0.3]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 20 20 50 0.3 0.01707136758984491 0.11760324356968294 0.003862708015158348 0.00779871315920437 0.027092565536409072 0.1269427383093226 0.037042697073384485 32 400 19\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 20, 20, 50, 0.5]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 20 20 50 0.5 0.08292116553348684 0.12259611263683905 0.006698127080777164 0.008116675540482513 0.10697970943144242 0.12958170436286293 0.030076224448587235 254 400 17\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 20, 20, 50, 0.7]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 20 20 50 0.7 0.052175181364608705 0.13798602433207724 0.012030802753832736 0.010137402090650914 0.020849692488882594 0.14057528441642397 0.06309777521377309 38 400 35\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 20, 20, 50, 0.9]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 20 20 50 0.9 0.039886283186423524 0.13160051269850148 0.01248188123971774 0.009108540750386857 0.0006230349211005974 0.14067872319450353 0.040509318107524124 1 400 13\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 20, 50, 50, 0.1]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 20 50 50 0.1 0.02888617799880155 0.1260237993920313 0.004434895253315655 0.005201121508981989 0.020017752388732254 0.1346738355116555 0.04014967290934657 94 1000 55\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 20, 50, 50, 0.3]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 20 50 50 0.3 0.028550954216988875 0.12126921899325817 0.005497781074018634 0.005184947640742134 0.010471155669866845 0.12605374894182803 0.03313702036375679 52 1000 41\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 20, 50, 50, 0.5]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 20 50 50 0.5 0.029558350751044862 0.11625799382988965 0.005633709105836813 0.004957894360389951 0.01025635792571164 0.12677402127875093 0.034750184667039066 43 1000 42\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 20, 50, 50, 0.7]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 20 50 50 0.7 0.025024318965251865 0.12175271088632206 0.0040963256408290466 0.005232934157442233 0.02370631837976604 0.12968667342762263 0.04084197794884414 91 1000 50\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 20, 50, 50, 0.9]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 20 50 50 0.9 0.04430666804435897 0.12566223044069194 0.008048565903815556 0.0054575137098521 0.00022983381200111352 0.13653390978981667 0.04443774074053182 2 1000 51\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 50, 20, 50, 0.1]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 50 20 50 0.1 0.03775726562777499 0.11591395252284817 0.006270697539274392 0.005137420832752026 1.8473212331896472e-06 0.11956951700633954 0.0377554183065418 1 1000 57\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 50, 20, 50, 0.3]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 50 20 50 0.3 0.02364341984522931 0.11430794178216362 0.0044479826830606225 0.004976375343348496 0.012119508159765213 0.11610998892472053 0.02973527743994478 64 1000 34\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 50, 20, 50, 0.5]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 50 20 50 0.5 0.028271165337810964 0.11106765331604904 0.005481972811854769 0.005033703772790457 0.006848350286150266 0.1126480101295591 0.02997818183278 50 1000 38\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 50, 20, 50, 0.7]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "Experiment on this dataset failed!\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 50, 20, 50, 0.9]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 50 20 50 0.9 0.029619390167561613 0.11834557386284274 0.005078990316391962 0.00537715741052758 0.00741459752000142 0.11846096055192563 0.035761327584900186 29 1000 52\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 50, 50, 50, 0.1]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 50 50 50 0.1 0.0338945360140826 0.11630617498735328 0.003901765832252259 0.003269237223579125 0.005939618282583346 0.12072653133738313 0.033867816355310984 114 2500 114\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 50, 50, 50, 0.3]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.100000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.050000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.010000\n",
      "0.1 0.5 50 50 50 0.3 0.04196127118883007 0.12490582965804993 0.004433574839535235 0.003602615157610666 0.005381583027233786 0.12806548364818185 0.042679678234608054 99 2500 125\n",
      "Now, Experiment With Parameters -- [0.1, 0.5, 50, 50, 50, 0.5]\n",
      "    Hyper-parameter lambda1 == lambda2 == 10.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 5.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 1.000000\n",
      "    Hyper-parameter lambda1 == lambda2 == 0.500000\n"
     ]
    }
   ],
   "source": [
    "for s1, s2, P, Q, N, roE, n_split, n_repeat in params_setup_list:\n",
    "    \n",
    "    print(\"Now, Experiment With Parameters -- %s\" % str([s1, s2, P, Q, N, roE]))\n",
    "    \n",
    "    #Averaging Hyper Params Out-Sample Performance Using SMRCE \n",
    "    \n",
    "    optimal_lambda_SMRCE = None \n",
    "    optimal_rmse_SMRCE = None\n",
    "    optimal_lambda_RIDGE = None\n",
    "    optimal_rmse_RIDGE = None\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        X, Y, B, CovX = data_generator1(s1, s2, P, Q, N, roE)\n",
    "    \n",
    "        for lambda_ in [10, 5, 1, 0.5, 0.1, 0.05, 0.01]:\n",
    "            print(\"    Hyper-parameter lambda1 == lambda2 == %3f\" % lambda_)\n",
    "\n",
    "            rmse_sum_SMRCE, rmse_sum_RIDGE = 0, 0\n",
    "\n",
    "            num = 0\n",
    "            for i in range(n_repeat):\n",
    "                for X_tr, Y_tr, X_te, Y_te in cross_split(X, Y, n_split):\n",
    "                    try:\n",
    "                        matrix_B_param, B_ridge = training(lambda_, lambda_, X_tr, Y_tr)\n",
    "                    except:\n",
    "#                         traceback.print_exc()\n",
    "                        # Data Set not work well for the hyper-parameter\n",
    "                        break\n",
    "                        \n",
    "\n",
    "                    #Predicting on Out-Sample\n",
    "                    Y_hat_SMRCE = X_te.dot(matrix_B_param)\n",
    "                    Y_hat_RIDGE = X_te.dot(B_ridge)\n",
    "\n",
    "                    rmse_SMRCE = np.sqrt(np.trace((Y_te - Y_hat_SMRCE).T.\\\n",
    "                                            dot(Y_te - Y_hat_SMRCE)))\n",
    "                    rmse_sum_SMRCE += rmse_SMRCE\n",
    "\n",
    "                    rmse_RIDGE = np.sqrt(np.trace((Y_te - Y_hat_RIDGE).T.\\\n",
    "                                            dot(Y_te - Y_hat_RIDGE)))\n",
    "                    rmse_sum_RIDGE += rmse_RIDGE\n",
    "\n",
    "                    num += 1\n",
    "            \n",
    "            if num == 0:\n",
    "                continue\n",
    "\n",
    "            avg_rmse_SMRCE = rmse_sum_SMRCE / num\n",
    "            avg_rmse_RIDGE = rmse_sum_RIDGE / num\n",
    "\n",
    "            if optimal_rmse_SMRCE is None or optimal_rmse_SMRCE > avg_rmse_SMRCE:\n",
    "                optimal_rmse_SMRCE = avg_rmse_SMRCE\n",
    "                optimal_lambda_SMRCE = lambda_\n",
    "\n",
    "            if optimal_rmse_RIDGE is None or optimal_rmse_RIDGE > avg_rmse_RIDGE:\n",
    "                optimal_rmse_RIDGE = avg_rmse_RIDGE\n",
    "                optimal_lambda_RIDGE = lambda_\n",
    "\n",
    "\n",
    "        # ---- Using Optimal Hyper-parameter Training On the whole Dataset\n",
    "        #     print(optimal_lambda_SMRCE, optimal_lambda_RIDGE)\n",
    "        try:\n",
    "            matrix_B_param, _ = training(optimal_lambda_SMRCE, \n",
    "                                         optimal_lambda_SMRCE, \n",
    "                                         X, Y)\n",
    "            _, matrix_B_ridge = training(optimal_lambda_RIDGE, \n",
    "                                         optimal_lambda_RIDGE,\n",
    "                                         X, Y)\n",
    "        except:\n",
    "            print(\"Experiment on this dataset failed!\")\n",
    "            break\n",
    "\n",
    "        matrix_bias_SMRCE = matrix_B_param - B\n",
    "        matrix_bias_RIDGE = matrix_B_ridge - B\n",
    "\n",
    "        element_n = B.shape[0] * B.shape[1]\n",
    "        mae_bias_SMRCE = l1_norm(matrix_bias_SMRCE) / element_n \n",
    "        mae_bias_RIDGE = l1_norm(matrix_bias_RIDGE) / element_n\n",
    "        rmse_bias_SMRCE = np.sqrt(np.trace(matrix_bias_SMRCE.T.dot(matrix_bias_SMRCE))) / element_n\n",
    "        rmse_bias_RIDGE = np.sqrt(np.trace(matrix_bias_RIDGE.T.dot(matrix_bias_RIDGE))) / element_n\n",
    "        l1_elem_SMRCE = l1_norm(matrix_B_param) / element_n\n",
    "        l1_elem_RIDGE = l1_norm(matrix_B_ridge) / element_n\n",
    "        l1_elem_B = l1_norm(B) / element_n\n",
    "        l0_elem_SMRCE = (matrix_B_param != 0).sum()\n",
    "        l0_elem_RIDGE = (matrix_B_ridge != 0).sum()\n",
    "        l0_elem_B = (B != 0).sum()\n",
    "\n",
    "        print(s1, s2, P, Q, N, roE, mae_bias_SMRCE, mae_bias_RIDGE, \n",
    "              rmse_bias_SMRCE, rmse_bias_RIDGE,\n",
    "              l1_elem_SMRCE, l1_elem_RIDGE, l1_elem_B, l0_elem_SMRCE, l0_elem_RIDGE, l0_elem_B)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
